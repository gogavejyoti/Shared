using var http = new HttpClient();
http.DefaultRequestHeaders.Add("api-key", azureApiKey);

var requestBody = new
{
    messages = new[]
    {
        new { role = "system", content = "You are a Workforce Management domain expert." },
        new { role = "user", content = prompt }
    },
    temperature = 0.4,
    max_tokens = 700,
    top_p = 1,
    frequency_penalty = 0,
    presence_penalty = 0,
    stream = true // Important: tells Azure OpenAI to return streamed response
};

var requestJson = JsonConvert.SerializeObject(requestBody);
var request = new HttpRequestMessage(HttpMethod.Post, $"{azureEndpoint}openai/deployments/{chatDeployment}/chat/completions?api-version={chatApiVersion}")
{
    Content = new StringContent(requestJson, Encoding.UTF8, "application/json")
};

// Use SendAsync instead of PostAsync
using var response = await http.SendAsync(request, HttpCompletionOption.ResponseHeadersRead);

if (!response.IsSuccessStatusCode)
{
    var error = await response.Content.ReadAsStringAsync();
    throw new Exception("ChatGPT error: " + error);
}

// Stream the content from response
using var stream = await response.Content.ReadAsStreamAsync();
using var reader = new StreamReader(stream);

var fullResponse = new StringBuilder();

while (!reader.EndOfStream)
{
    var line = await reader.ReadLineAsync();
    if (!string.IsNullOrWhiteSpace(line) && line.StartsWith("data: "))
    {
        var json = line.Substring("data: ".Length);
        if (json.Trim() == "[DONE]") break;

        dynamic chunk = JsonConvert.DeserializeObject(json);
        string content = chunk?.choices?[0]?.delta?.content;
        if (!string.IsNullOrEmpty(content))
        {
            fullResponse.Append(content);
        }
    }
}

return fullResponse.ToString();
